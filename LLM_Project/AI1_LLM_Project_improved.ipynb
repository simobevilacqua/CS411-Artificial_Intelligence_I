{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZfw6hVQh0Cv"
   },
   "source": [
    "# Deep Dive into Deep Learning: Fine-tuning a Large Language Model for Housing Price Prediction\n",
    "\n",
    "**Welcome to the world of Large Language Models!**\n",
    "\n",
    "In this project, you'll get a hands-on in building a state-of-the-art AI system capable of predicting housing prices. This challenge will immerse you in the core concepts of modern Natural Language Processing (NLP).\n",
    "\n",
    "## Prerequisites: A Foundation for Exploration\n",
    "\n",
    "This project assumes a basic familiarity with Python programming and Machine Learning.  While prior experience with deep learning libraries is beneficial, it's not strictly required, as we'll guide you through the essential concepts and techniques.\n",
    "\n",
    "**Here's a breakdown of the key prerequisites and resources to help you get started:**\n",
    "\n",
    "### 1. Machine Learning and Deep Learning:  The Power of Pattern Recognition\n",
    "\n",
    "*   **Machine Learning: From the Data Up**\n",
    "  \n",
    "  Machine learning algorithms grow models that realize rules and patterns from data without explicit programming. That is, instead of implementing rules based on human knowledge, we feed these algorithms large datasets, allowing them to identify trends on their own, with little expert's involvement. The aim of doing Machine Learning is to make predictions that are consistent with past and future observations.\n",
    "*   **Deep Learning: A Revolution in Artificial Intelligence**\n",
    "\n",
    "  Deep learning represents a powerful subset of machine learning that utilizes artificial neural networks – with computational structures inspired by the human brain – to model intricate patterns and relationships within data.  Deep learning has driven remarkable breakthroughs in computer vision, natural language processing, and countless other domains.\n",
    "    *   **Further Reading:** [Deep Learning](https://www.deeplearningbook.org/) by Ian Goodfellow, Yoshua Bengio, and Aaron Courville provides a comprehensive introduction to the field.\n",
    "\n",
    "### 2. The Natural Language Modeling Task: Teaching Machines to Understand Human Language\n",
    "\n",
    "*   **Decoding the Essence of Language**\n",
    "\n",
    "  Natural language processing (NLP) focuses on bridging the gap between human language and computer understanding. It encompasses a wide range of tasks, from simple text classification to machine translation and question answering.\n",
    "*   **The Power of Deep Learning in NLP**\n",
    "\n",
    "  Deep learning models, particularly those based on the Transformer architecture (more on that below!), have revolutionized NLP. Their ability to capture long-range semantic dependencies and intricate syntactic structures has led to significant improvements in language understanding and generation.\n",
    "    *   **Further Reading:**  The Stanford CS224N course ([Website](http://web.stanford.edu/class/cs224n/)) offers slides and notes that serve as a fantastic deep dive into NLP with deep learning.\n",
    "\n",
    "### 3. Transformers: The Architecture Reshaping NLP\n",
    "\n",
    "*   **Beyond Recurrent Networks**\n",
    "\n",
    "  Traditional recurrent neural networks (RNNs) faced challenges in processing long sequences of text due to their sequential nature. Transformers, introduced in the groundbreaking paper \"Attention Is All You Need\" ([Paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)), addressed these limitations by leveraging an innovative self-attention mechanism.\n",
    "*   **Attention is All You Need**  \n",
    "\n",
    "  Self-attention allows the model to weigh the importance of different words in a sentence when processing information, enabling it to capture relationships and dependencies across long distances efficiently. This breakthrough architecture has become the workhorse of modern NLP solutions.\n",
    "\n",
    "  We will be working with the T5 model in this project. It is a generic encoder-decoder Transformer model commonly used by researchers and academics to study the extend of machine language modeling.\n",
    "\n",
    "### 4. Hugging Face, PyTorch, and the Power of Open-Source AI\n",
    "\n",
    "*   **Hugging Face Transformers: Your Gateway to NLP**\n",
    "\n",
    "  Hugging Face provides a powerful and user-friendly library ([Hugging Face Documentation](https://huggingface.co/docs/transformers/index)) that simplifies the use of pre-trained Transformer models for various NLP tasks.  You'll use it extensively throughout this project.\n",
    "*   **PyTorch: A Powerful Auto-Diff Framework**\n",
    "\n",
    "  PyTorch is a widely adopted deep learning framework known for its dynamic computation graph and intuitive API. Its auto-differentiation capabilities streamline the process of calculating gradients, a critical aspect of training large neural networks with complex computation structures.\n",
    "    *   **Further Reading:**  The official [PyTorch Tutorials](https://pytorch.org/tutorials/) are an excellent resource for getting started.\n",
    "\n",
    "### 5. The Deep Learning Training Pipeline: A Step-by-Step Guide\n",
    "\n",
    "1.  **Data Preparation:**  Transforming raw data into a format suitable for training a deep learning model, often involving cleaning missing or invalid data values, data normalization, and splitting into training, validation, and test sets.\n",
    "2.  **Model Selection:** Choosing an appropriate model architecture (in our case, a pre-trained Transformer) based on the task/dataset characteristics. This is where the expert's intuition comes in, but at a very high level.\n",
    "3.  **Loss Function and Optimizer:** Defining a loss function that continuously quantifies the model's errors during training and selecting an optimization algorithm (typically Stochastic Gradient Descent and variations) to adjust the model's parameters and minimize this loss function.\n",
    "4.  **Training:** Feeding the training data through the model - in batches or all at once, calculating the loss, and using backpropagation to update the model's weights. We typically need to do these steps many times.\n",
    "5.  **Validation:**  Evaluating the model's performance on a separate validation set to tune hyperparameters and prevent overfitting (where the model memorizes the training data so it fails to generalize to unseen examples).\n",
    "6.  **Testing:** Assessing the model's final performance on a held-out test set to provide an unbiased estimate of its generalization correctness. These test examples should not have been used in tuning the model's parameters nor its hyperparameters.\n",
    "\n",
    "### 6. Project Goals: Unveiling the Apparent Magic of Deep Learning\n",
    "\n",
    "In this project, our aim is to provide you with practical experience and a deeper understanding of:\n",
    "\n",
    "*   **Fine-tuning Pretrained Language Models:** You'll learn how to adapt a powerful pre-trained language model (T5) to a specific task, scientific question answering, by training it on a relevant dataset.\n",
    "*   **Hyperparameter Tuning:** Experimenting with different training settings to optimize your model's performance.\n",
    "*   **Evaluating Model Performance:** Using appropriate metrics to assess your model's effectiveness.\n",
    "*   **Model Interpretability:** Gaining insights into how your model makes decisions, particularly by visualizing the attention mechanism within the Transformer architecture.\n",
    "\n",
    "**To be successful at this project's learning goals, we expect that you read the description of each section, run every code block sequentially from top to bottom (you can check if your implementation is correct by compare and contrast with the provided outputs), and complete the TODOs and final report. In addition, we highly encourage you to break free from the provided starter code and implement additional features for data augmnetation, model interpretability and visualization, etc. Happy deep diving!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PrtlB17HhIhY",
    "outputId": "266867a2-ccaa-4641-cac3-87edce4f7b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tqdm # Install necessary libraries (Run this cell first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aJGPc-OHwx--"
   },
   "outputs": [],
   "source": [
    "import os # For interacting with the operating system\n",
    "import pandas as pd # For data storage, manipulation, and fast analysis\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # For the T5 model\n",
    "from torch.utils.data import Dataset, DataLoader # For making custom datasets\n",
    "from tqdm import tqdm # For visualizing training/testing progress bar\n",
    "import torch # PyTorch library for deep learning\n",
    "import sklearn # For fast initialization of machine learning models and algorithms\n",
    "import matplotlib.pyplot as plt # For plotting graphs\n",
    "import seaborn as sns # For plotting heatmaps\n",
    "import warnings # For printing warning messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTSVPXxMhSzF"
   },
   "source": [
    "# Part 1: Data Preparation & Preprocessing\n",
    "1. Load the Boston Housing Dataset\n",
    "\n",
    "Download the [Boston Housing Dataset](https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/input), upload it to your Colab environment, and use the correct path name to programmatically access that file (should be a csv file) during runtime. If you would like to learn what the column names mean or the dataset origin, please visit [this link](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) (it is highly recommended that you intimately understand the dataset you are working with).\n",
    "\n",
    "Remember that our task is to train a model that can predict the price of houses given other attributes/features of those houses. That is, the last column of this data is what we aim to make the model correctly predict given the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpXyjjaxhfMr",
    "outputId": "99a15333-e1b7-4032-dc21-6018831add22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  MEDV  \n",
      "0     15.3  396.90   4.98  24.0  \n",
      "1     17.8  396.90   9.14  21.6  \n",
      "2     17.8  392.83   4.03  34.7  \n",
      "3     18.7  394.63   2.94  33.4  \n",
      "4     18.7  396.90   5.33  36.2  \n",
      "\n",
      "Dataset dimensions: (506, 14)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    int64  \n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "data = pd.read_csv('./housing.csv', header=None, delimiter=r\"\\s+\", names=column_names) # Replace with the appropriate path if necessary\n",
    "\n",
    "# Inspect the dataframe\n",
    "print(data.head()) # Display the first few rows of the dataset\n",
    "print()\n",
    "print(\"Dataset dimensions:\", data.shape) # Display the number of rows and columns in the dataset\n",
    "print()\n",
    "print(data.info()) # Display information about the dataset (data types, missing values of each column, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--va-j6DhwTX"
   },
   "source": [
    "2. Define a function to transform the dataset\n",
    "\n",
    "If you have been in Machine Learning for some time, you might have notice that price prediction is a regression task, which means the model should output continuous numerical values. However, T5 is a language model, which means it outputs discrete text tokens. We will handle this discrepancy in modality in the later section. For now, we need to convert the given numerical data format to the textual data format so our T5 model can consume this data.\n",
    "\n",
    "We need to do the following data processing steps:\n",
    "-  Combining Text: We combine the features into a single text string because the T5 model expects a single natural language string as input. The T5 model also outputs a single natural language string so we also need to make the ground-truth label a text string so we can supervise the model outputs versus the ground-truth labels.\n",
    "- Pandas DataFrame: We convert this data into a [Pandas DataFrame](https://pandas.pydata.org/docs/getting_started/index.html#getting-started) for efficient data manipulation and to easily feed the data into our training pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "x_qffxrnhtwv"
   },
   "outputs": [],
   "source": [
    "def reformat_dataset(data: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    formatted_data = []\n",
    "    for _, row in data.iterrows():\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: create the input string from part of the values in 'row'.\n",
    "        # You must not give the model the last column value\n",
    "        # as that is what we want the model to predict.\n",
    "        input_string = ', '.join([f\"{row[col]}\" for col in data.columns[:-1]])\n",
    "        ########################################################################\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: create the output string from part of the values in 'row'.\n",
    "        # This string should contain the value in\n",
    "        # the last column without any additional text so we can easily convert\n",
    "        # the trained model's output to floating point values later\n",
    "        output_string = str(row[data.columns[-1]])\n",
    "        ########################################################################\n",
    "\n",
    "        formatted_data.append((input_string, output_string))\n",
    "\n",
    "    return pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5UQ6rbimj4oh"
   },
   "source": [
    "3. Split the data into training, validation, and test sets\n",
    "\n",
    "It's essential to divide our data into three separate sets: training, validation, and test. Let's understand why this is crucial:\n",
    "\n",
    "- Training Data:  This is the largest portion of our data, used to directly train the model's parameters.\n",
    "- Validation Data: Held separate from the training data, this set is used to fine-tune the model's hyperparameters (like learning rate, batch size, epochs) and get an early sense of its performance on unseen data.\n",
    "- Test Data: The most important subset! It's kept hidden from the model during training and validation and used only at the very end to provide an unbiased evaluation of the final model's performance.\n",
    "\n",
    "To efficiently feed our data to the T5 model during training, we'll create a custom dataset class and a data collate function. They handle the extraction and tokenization of our text data and organizes it into a format readily consumable by the PyTorch DataLoader.\n",
    "\n",
    "**Key Benefits of Defining a Custom Dataset Class and a Data Collate Function**\n",
    "- Organized Data Loading:  Simplifies the process of accessing and preparing data batches during training. Especially when the data may be coming in various format (e.g. dictionaries, lists, dataframes, etc.).\n",
    "- On-the-Fly Tokenization:  Performs tokenization (more on this in the next section) and sequence length padding efficiently when a data sample is requested.\n",
    "- Integration with DataLoader:  Works seamlessly with PyTorch's DataLoader for data multi-processing and data shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tDt9e509WDlH"
   },
   "outputs": [],
   "source": [
    "class OurDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, at_index: int) -> dict:\n",
    "        item_at_index = dict.fromkeys(['text', 'label'])\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Get the input string at the given index out of the Pandas\n",
    "        # DataFrame and add it into a dictionary\n",
    "        # store this input string with the key 'text'\n",
    "        item_at_index['text'] = self.data.loc[at_index][0]\n",
    "        ########################################################################\n",
    "\n",
    "        ########################################################################\n",
    "        # TODO: Get the output string at the given index out of the Pandas\n",
    "        # DataFrame and add it into a dictionary\n",
    "        # store this output string with the key 'label'\n",
    "        item_at_index['label'] = self.data.loc[at_index][1]\n",
    "        ########################################################################\n",
    "\n",
    "        # Return the item dictionary to the dataloader for batching\n",
    "        return item_at_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frHr6D4Ij2Sz",
    "outputId": "7f2e6ef4-9ad8-4284-e5ea-bcfc7fcbc8e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 404\n",
      "First train datapoint\n",
      " {'text': '15.0234, 0.0, 18.1, 0.0, 0.614, 5.304, 97.3, 2.1007, 24.0, 666.0, 20.2, 349.48, 24.91', 'label': '12.0'}\n",
      "Validation data size: 51\n",
      "First val datapoint\n",
      " {'text': '0.00632, 18.0, 2.31, 0.0, 0.538, 6.575, 65.2, 4.09, 1.0, 296.0, 15.3, 396.9, 4.98', 'label': '24.0'}\n",
      "Test data size: 51\n",
      "First test datapoint\n",
      " {'text': '0.13914, 0.0, 4.05, 0.0, 0.51, 5.572, 88.5, 2.5961, 5.0, 296.0, 16.6, 396.9, 14.69', 'label': '23.1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split and process each partition of the dataset individually\n",
    "# Train data is used to train model's parameters\n",
    "# Val data is used pick model's hyperparameters\n",
    "# Test data is used to evaluate the model's performance\n",
    "train_data, val_test_data = train_test_split(data, test_size=0.2, random_state=42)  # Split into train and temp sets\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)  # Split temp into val and test sets\n",
    "\n",
    "# Apply the reformatting function\n",
    "train_data = reformat_dataset(train_data)\n",
    "val_data = reformat_dataset(val_data)\n",
    "test_data = reformat_dataset(test_data)\n",
    "\n",
    "# Create our custom datasets\n",
    "train_data = OurDataset(train_data)\n",
    "val_data = OurDataset(val_data)\n",
    "test_data = OurDataset(test_data)\n",
    "\n",
    "print(\"Training data size:\", len(train_data))\n",
    "print(\"First train datapoint\\n\", train_data[0])\n",
    "print(\"Validation data size:\", len(val_data))\n",
    "print(\"First val datapoint\\n\", val_data[0])\n",
    "print(\"Test data size:\", len(test_data))\n",
    "print(\"First test datapoint\\n\", test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "m12KcsAyxw5o"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")  # Load the tokenizer for the 'collate_fn' context\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Tokenize datapoints in batch, we do padding depending on longest sequence\n",
    "    # in the batch\n",
    "    text = tokenizer([datapoint['text'] for datapoint in batch], padding=True, return_tensors='pt')\n",
    "    labels = tokenizer([datapoint['label'] for datapoint in batch], padding=True, return_tensors='pt')\n",
    "    return {'input_ids': text['input_ids'], 'attention_mask': text['attention_mask'], 'labels': labels['input_ids']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfyeiAq-kDMP"
   },
   "source": [
    "# Part 2: Model Fine-tuning\n",
    "\n",
    "1. Load the pre-trained T5-small model and tokenizer\n",
    "\n",
    "In this project, we'll be working with the \"T5-small\" model, a lightweight but powerful Transformer-based language model developed by Google.  Let's see what makes T5 ([Documentation](https://huggingface.co/docs/transformers/en/model_doc/t5)) special and why it's well-suited for our task.\n",
    "\n",
    "**T5 Architecture and Training: A Versatile Language Model**\n",
    "\n",
    "- Encoder-Decoder Structure:  As introduced in [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf), T5 consists of two main components: an encoder that processes the input text into a context vector and a decoder that autoregressively generates the output text based on the context vector and generated texts.\n",
    "- Text-to-Text Framework: What sets T5 apart is its pre-training approach. It was pre-trained on a massive dataset of text-to-text tasks, where it learns various NLP tasks (translation, summarization, question answering) in a unified text-to-text format.\n",
    "    - C4 Dataset:  T5 is pre-trained on the [Colossal Clean Crawled Corpus (C4)](https://huggingface.co/datasets/allenai/c4), a vast dataset of text and code scraped from the entier internet. This extensive and diverse training data makes T5 remarkably versatile and capable of adapting to various NLP tasks.\n",
    "\n",
    "**The Role of the Tokenizer**\n",
    "\n",
    "- Bridging the Gap Between Text and Vectors:  Deep learning models operate on numerical vectors, not raw text. The tokenizer acts as a translator between the two.\n",
    "- Vocabulary and Tokenization:  It has a predefined vocabulary (a mapping between words or subwords and numerical IDs). The tokenizer splits the input text into individual tokens (words or subwords) and converts them into their corresponding numerical IDs. The model can then convert these IDs into the corresponding vector using its trainable look-up table.\n",
    "\n",
    "You may wonder: how can these vectors stand in place of words? The magic happened when the model was pre-trained on the internet, it learns to map semantically related words (typically used in similar contexts) to similar vectors, while words that are unrelated are mapped to othorgonal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01gdMy0jkBCd",
    "outputId": "9adfa13b-7488-4fde-961b-5e94abaad3a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 60,506,624 trainable parameters.\n",
      "Tokenizer has a vocabulary of 32100 tokens.\n",
      "\n",
      "Tokens of the sentence \"I wish birds can perform the blues when Spring comes!\" are:\n",
      "['▁I', '▁wish', '▁birds', '▁can', '▁perform', '▁the', '▁blue', 's', '▁when', '▁Spring', '▁comes', '!']\n",
      "\n",
      "Tokens of the sentence \"0.123, 903, 100, -43.32\" are:\n",
      "['▁0.', '123', ',', '▁90', '3,', '▁100', ',', '▁', '-', '43', '.', '32']\n",
      "\n",
      "Vocab IDs of the sentence \"I wish birds can perform the blues when Spring comes!\" are:\n",
      "[27, 1663, 6331, 54, 1912, 8, 1692, 7, 116, 4328, 639, 55, 1]\n",
      "\n",
      "Vocab IDs of the sentence \"0.123, 903, 100, -43.32\" are:\n",
      "[4097, 14574, 6, 2777, 6355, 910, 6, 3, 18, 4906, 5, 2668, 1]\n",
      "\n",
      "Cosine similarity score between \"cat\" and \"kitten\": 0.4431859254837036\n",
      "\n",
      "Cosine Similarity score between \"cat\" and \"high\": 0.0012265145778656006\n",
      "\n",
      "Cosine Similarity score between \"high\" and \"low\": 0.6634554862976074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")  # Load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "model.to(device)  # Move the model to the device\n",
    "model_p_count = sum([p.numel() for p in filter(lambda p: p.requires_grad, model.parameters())])\n",
    "\n",
    "print(f\"Model has {model_p_count:,} trainable parameters.\")  # Print the number of trainable parameters in T5\n",
    "print(f\"Tokenizer has a vocabulary of {len(tokenizer.get_vocab())} tokens.\") # Print the tokenizer's states\n",
    "print()\n",
    "\n",
    "# Let's see how to tokenizer works on example strings\n",
    "# You may notice that a token is approximately a word (but not really),\n",
    "# this is so that the model learns the compositionality of the human language\n",
    "s1 = \"I wish birds can perform the blues when Spring comes!\"\n",
    "s2 = \"0.123, 903, 100, -43.32\"\n",
    "print(f\"Tokens of the sentence \\\"{s1}\\\" are:\\n{tokenizer.tokenize(s1)}\")\n",
    "print()\n",
    "print(f\"Tokens of the sentence \\\"{s2}\\\" are:\\n{tokenizer.tokenize(s2)}\")\n",
    "print()\n",
    "\n",
    "# Let's see the IDs those tokens are associated with\n",
    "# You may notice there is an extra token ID 1 at the end of the 2 sentences,\n",
    "# that is the special end-of-sentence token that allows the model to learn\n",
    "# when to stop prolonging the sentence\n",
    "print(f\"Vocab IDs of the sentence \\\"{s1}\\\" are:\\n{tokenizer(s1)['input_ids']}\")\n",
    "print()\n",
    "print(f\"Vocab IDs of the sentence \\\"{s2}\\\" are:\\n{tokenizer(s2)['input_ids']}\")\n",
    "print()\n",
    "\n",
    "# Let's check the embedding of two similar words versus two disimilar words\n",
    "# We know these words are to be tokenized into single tokens and we ignore the\n",
    "# end-of-sentence token\n",
    "word1 = \"cat\"\n",
    "word2 = \"kitten\"\n",
    "word3 = \"high\"\n",
    "word4 = \"low\"\n",
    "embedded_vector1 = model.get_input_embeddings()(torch.tensor([tokenizer(word1)['input_ids'][0]], device=model.get_input_embeddings().weight.device))\n",
    "embedded_vector2 = model.get_input_embeddings()(torch.tensor([tokenizer(word2)['input_ids'][0]], device=model.get_input_embeddings().weight.device))\n",
    "embedded_vector3 = model.get_input_embeddings()(torch.tensor([tokenizer(word3)['input_ids'][0]], device=model.get_input_embeddings().weight.device))\n",
    "embedded_vector4 = model.get_input_embeddings()(torch.tensor([tokenizer(word4)['input_ids'][0]], device=model.get_input_embeddings().weight.device))\n",
    "# The cosine similarity will return a value between -1 and 1:\n",
    "# a value closer to 1 indicates very aligned,\n",
    "# closer to -1 means very disaligned,\n",
    "# and closer to 0 means unrelated words\n",
    "print(f\"Cosine similarity score between \"\n",
    "      f\"\\\"{word1}\\\" and \\\"{word2}\\\": {torch.nn.functional.cosine_similarity(embedded_vector1, embedded_vector2).item()}\")\n",
    "print()\n",
    "print(f\"Cosine Similarity score between \"\n",
    "      f\"\\\"{word1}\\\" and \\\"{word3}\\\": {torch.nn.functional.cosine_similarity(embedded_vector1, embedded_vector3).item()}\")\n",
    "print()\n",
    "print(f\"Cosine Similarity score between \"\n",
    "      f\"\\\"{word3}\\\" and \\\"{word4}\\\": {torch.nn.functional.cosine_similarity(embedded_vector3, embedded_vector4).item()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aieBjlOTkLGF"
   },
   "source": [
    "2. Define training hyperparameters\n",
    "\n",
    "Now that we've loaded our pre-trained T5 model, let's dive into the process of fine-tuning it on our dataset. A crucial part of this process involves understanding and setting appropriate hyperparameters.\n",
    "\n",
    "**Hyperparameter Deep Dive: Navigating the Training Landscape**\n",
    "\n",
    "Hyperparameters are like the control knobs of our training process. They influence how the model learns from the data.  Let's explore three essential hyperparameters:\n",
    "\n",
    "- Learning Rate: This hyperparameter determines how big of a step we update the model's parameters in the direction of minimizing the model's loss during each training iteration.\n",
    "- Smaller Learning Rate (e.g., 1e-5): The model learns more slowly but might find a more precise solution.\n",
    "- Larger Learning Rate (e.g., 1e-3): Faster learning, but the model might overshoot the optimal solution and not converge well.\n",
    "- Batch Size: Instead of feeding the entire training dataset to the model at once, we divide it into smaller groups called batches.\n",
    "- Smaller Batch Size (e.g., 8, 16): Requires less memory, but updates to the model's parameters can be noisy.\n",
    "- Larger Batch Size (e.g., 32, 64): More computationally efficient, smoother updates, but might require more memory.\n",
    "- Epochs: An epoch represents one complete pass through the entire training dataset.\n",
    "- Too Few Epochs: The model might underfit the data, meaning it hasn't learned the patterns well enough.\n",
    "- Too Many Epochs: The model might overfit the data, memorizing the training examples but performing poorly on unseen data.\n",
    "\n",
    "Finding the optimal balance for these hyperparameters often involves experimentation and observing the model's performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "R61j0nPwkJOO"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4  # Change this as you like\n",
    "batch_size = 16  # Change this as you like\n",
    "epochs = 150  # Change this as you like, you might want to train much longer to get adequate accuracy\n",
    "\n",
    "# Regularization with weight decay\n",
    "weight_decay = 1e-4  # Regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChDBXDQykRc9"
   },
   "source": [
    "3. Define training loop\n",
    "\n",
    "Now that we have our data, model, and hyperparameters set, it's time to bring them all together in the training loop. This loop is where the magic happens - it's where our T5 model learns from the data to become proficient in housing price prediction.\n",
    "\n",
    "**Training Phase**\n",
    "1. Set the model to training mode\n",
    "2. Clear any previously calculated gradients\n",
    "3. Extract data from dataloader and move them to the correct device\n",
    "4. Forward Pass: Calculate the model's predictions\n",
    "5. Calculate how far off the predictions are\n",
    "6. Backward Pass: Calculate gradients for each parameter\n",
    "7. Update Model Parameters:  Adjust model parameters to minimize the loss\n",
    "\n",
    "**Validation Phase**\n",
    "1. After each epoch, we evaluate the model's progress on the validation set\n",
    "2. Set the model to evaluation mode (no parameter updates)\n",
    "3. Disable gradient calculation to save memory\n",
    "4. Similar to the training loop, but we aim to calculate the matching between model's predictions and ground-truth labels without any parameter adjustments\n",
    "\n",
    "Normally, evaluating the next-token prediction capability of a language model requires the [BLEU and ROUGE metrics](https://medium.com/@raniahossam/cracking-the-code-of-text-evaluation-unveiling-the-magic-of-rouge-metrics-bb0c687f479f). However, in our case, this metric would not be appropriate as we want the error between the model's numerical values versus the ground-truth price.\n",
    "\n",
    "For example, the model's prediction of \"cat.2\" versus a ground-truth label of \"245.2\" should be a 0 accuracy score in our case instead of a 0.5 score that the ROUGE metric would assign. Instead, we must convert the model's output and ground-truth label into numerical values, then using an appropriate regression metric - [R-squared](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html) - to evaluate the model's performance (it is highly recommended that you understand how this metric behaves for certain model's behaviors so you can answer questions in the final report).\n",
    "\n",
    "Hint: If your implementation is correct so far, you should expect the model to fail to output (only) floating-point numbers at first, which is considered negative infinity validation score for obvious reasons, and only output numbers as the training progresses (but very lousy numbers), which allows for a non-infinity but moderately large negative validation score. As the model gets better at predicting house prices, you should see the validation score becomes positive and converges toward 1.\n",
    "\n",
    "**Checkpointing: Model saving and loading**\n",
    "\n",
    "Training LLMs can take a long time, sometimes hours or days! Checkpointing helps us to:\n",
    "\n",
    "- Save Our Progress:  Regularly saving checkpoints allows us to resume training from the last saved point if an interruption occurs (e.g., power outage, system crash).\n",
    "- Capture the Best Model: By saving the model with the highest validation score so far, we can keep track of our best-performing model during training while avoiding training degradation.\n",
    "\n",
    "**IMPORTANT NOTE** If you left your Colab environment unattended for some time, it may delete your saved files. I recommend that you regularly backup your files by downloading them onto your computer's drive once in a while, and reupload them to Colab if your files are deleted by Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LmmExSfixzvn"
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = './trained_model.pth'\n",
    "DATALOADER_PATH = './dataloaders.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "VxNqv9JeV8GN"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_dataloader, val_dataloader, epochs, best_accuracy):\n",
    "    \"\"\"Trains the model and evaluates on the validation set. Returned trained model and loss/validation progress.\"\"\"\n",
    "    loss_progress = []\n",
    "    val_progress = []\n",
    "    for epoch in range(start_epoch - 1, epochs):\n",
    "        model.train()  # Trigger training mode (enable gradient tracking)\n",
    "        total_loss = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch + 1}', leave=False)\n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            # Get necessary arguments out of 'batch', feed them to model, to obtain the model's output\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            model_outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = model_outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})  # Update progress bar\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        loss_progress.append(avg_train_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Avg. Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # Trigger testing mode (disable gradient tracking)\n",
    "        total_val_accuracy = 0\n",
    "        progress_bar = tqdm(val_dataloader, desc=f'Epoch {epoch + 1}', leave=False)\n",
    "        for batch in progress_bar:\n",
    "            # Get necessary arguments out of 'batch', feed them to model, to obtain the model's output\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Call HuggingFace's special 'generate' method to do autoregressive sampling of next tokens\n",
    "            # Note that this method is not differentiable/trainable as it performs discrete operations\n",
    "            # such as token sampling and sequence path searching. Documentation here:\n",
    "            # https://huggingface.co/docs/transformers/en/main_classes/text_generation\n",
    "            generate_outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=10)\n",
    "\n",
    "            decoded_preds = tokenizer.batch_decode(generate_outputs, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # Compute the R-squared score between the predicted strings and label strings\n",
    "            # We turn these strings into float for the R-squared computation\n",
    "            # but if model's output cannot be converted to a float,\n",
    "            # we can consider that an infinite error (accuracy = -infinity)\n",
    "            try:\n",
    "              predicted_values = [float(pred) for pred in decoded_preds]\n",
    "              actual_values = [float(label) for label in decoded_labels]\n",
    "              val_score = sklearn.metrics.r2_score(predicted_values, actual_values)\n",
    "            except ValueError:\n",
    "              val_score = float('-inf')\n",
    "            total_val_accuracy += val_score\n",
    "            progress_bar.set_postfix({'accuracy': val_score})  # Update progress bar\n",
    "\n",
    "        val_accuracy = total_val_accuracy / len(val_dataloader)\n",
    "        val_progress.append(val_accuracy)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Avg. Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Best-so-far Model Checkpointing\n",
    "        if val_accuracy >= best_accuracy:\n",
    "            print(f\"New latest and best accuracy! Saving model checkpoint to {CHECKPOINT_PATH}\")\n",
    "            best_accuracy = val_accuracy\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_train_loss,\n",
    "                'accuracy': best_accuracy,\n",
    "            }, CHECKPOINT_PATH)\n",
    "\n",
    "    return model, loss_progress, val_progress  # Return the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i5nRz6z1kPfT",
    "outputId": "dc529e42-566c-4b0e-9b58-0a860d62f27e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-5d7f818df78f>:17: UserWarning: \n",
      "\n",
      "No model checkpoint found.\n",
      "Starting from scratch.\n",
      "  warnings.warn(\"\\n\\nNo model checkpoint found.\\nStarting from scratch.\")\n",
      "<ipython-input-29-5d7f818df78f>:36: UserWarning: \n",
      "\n",
      "Starting with new data order and data slit.\n",
      "  warnings.warn(\"\\n\\nStarting with new data order and data slit.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 - Avg. Training Loss: 5.2210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 - Avg. Validation Accuracy: -inf\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 - Avg. Training Loss: 2.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 - Avg. Validation Accuracy: -1.6322\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 - Avg. Training Loss: 2.1555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 - Avg. Validation Accuracy: -90.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 - Avg. Training Loss: 1.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 - Avg. Validation Accuracy: -90.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 - Avg. Training Loss: 1.8905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 - Avg. Validation Accuracy: -90.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 - Avg. Training Loss: 1.8339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 - Avg. Validation Accuracy: -76.0458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 - Avg. Training Loss: 1.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 - Avg. Validation Accuracy: -204.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 - Avg. Training Loss: 1.8657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 - Avg. Validation Accuracy: -67.2887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 - Avg. Training Loss: 1.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 - Avg. Validation Accuracy: -24.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 - Avg. Training Loss: 1.6769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 - Avg. Validation Accuracy: -16.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 - Avg. Training Loss: 1.7574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 - Avg. Validation Accuracy: -3.7459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 - Avg. Training Loss: 1.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 - Avg. Validation Accuracy: -1.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 - Avg. Training Loss: 1.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 - Avg. Validation Accuracy: -1.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 - Avg. Training Loss: 1.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 - Avg. Validation Accuracy: -1.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 - Avg. Training Loss: 1.6451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 - Avg. Validation Accuracy: -2.9428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 - Avg. Training Loss: 1.6112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 - Avg. Validation Accuracy: -1.3689\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 - Avg. Training Loss: 1.5933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 - Avg. Validation Accuracy: -1.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 - Avg. Training Loss: 1.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 - Avg. Validation Accuracy: -1.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 - Avg. Training Loss: 1.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 - Avg. Validation Accuracy: -1.3549\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 - Avg. Training Loss: 1.5414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 - Avg. Validation Accuracy: -0.9794\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 - Avg. Training Loss: 1.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 - Avg. Validation Accuracy: -1.3178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 - Avg. Training Loss: 1.5682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 - Avg. Validation Accuracy: -1.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 - Avg. Training Loss: 1.5739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 - Avg. Validation Accuracy: -0.6350\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 - Avg. Training Loss: 1.5237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 - Avg. Validation Accuracy: -0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 - Avg. Training Loss: 1.5812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 - Avg. Validation Accuracy: -0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 - Avg. Training Loss: 1.4690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 - Avg. Validation Accuracy: -0.5824\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 - Avg. Training Loss: 1.4374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 - Avg. Validation Accuracy: -0.4132\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150 - Avg. Training Loss: 1.4689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150 - Avg. Validation Accuracy: -0.2793\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150 - Avg. Training Loss: 1.4679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150 - Avg. Validation Accuracy: -0.1208\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150 - Avg. Training Loss: 1.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150 - Avg. Validation Accuracy: -0.4687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150 - Avg. Training Loss: 1.3609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150 - Avg. Validation Accuracy: -0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150 - Avg. Training Loss: 1.4108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150 - Avg. Validation Accuracy: -0.2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150 - Avg. Training Loss: 1.3822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150 - Avg. Validation Accuracy: -0.0608\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150 - Avg. Training Loss: 1.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150 - Avg. Validation Accuracy: -0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150 - Avg. Training Loss: 1.3169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150 - Avg. Validation Accuracy: 0.1068\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150 - Avg. Training Loss: 1.3580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150 - Avg. Validation Accuracy: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150 - Avg. Training Loss: 1.2937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150 - Avg. Validation Accuracy: 0.2243\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150 - Avg. Training Loss: 1.2898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150 - Avg. Validation Accuracy: 0.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150 - Avg. Training Loss: 1.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150 - Avg. Validation Accuracy: 0.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150 - Avg. Training Loss: 1.2952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150 - Avg. Validation Accuracy: 0.2916\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150 - Avg. Training Loss: 1.2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150 - Avg. Validation Accuracy: 0.1447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150 - Avg. Training Loss: 1.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150 - Avg. Validation Accuracy: 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150 - Avg. Training Loss: 1.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150 - Avg. Validation Accuracy: 0.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150 - Avg. Training Loss: 1.2489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150 - Avg. Validation Accuracy: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150 - Avg. Training Loss: 1.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150 - Avg. Validation Accuracy: 0.3791\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150 - Avg. Training Loss: 1.1934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150 - Avg. Validation Accuracy: 0.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150 - Avg. Training Loss: 1.1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150 - Avg. Validation Accuracy: 0.2304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150 - Avg. Training Loss: 1.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150 - Avg. Validation Accuracy: 0.4222\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150 - Avg. Training Loss: 1.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150 - Avg. Validation Accuracy: 0.4261\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150 - Avg. Training Loss: 1.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150 - Avg. Validation Accuracy: 0.4081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150 - Avg. Training Loss: 1.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150 - Avg. Validation Accuracy: 0.4120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150 - Avg. Training Loss: 1.1462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150 - Avg. Validation Accuracy: 0.3535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150 - Avg. Training Loss: 1.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150 - Avg. Validation Accuracy: 0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150 - Avg. Training Loss: 1.1278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150 - Avg. Validation Accuracy: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/150 - Avg. Training Loss: 1.0943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/150 - Avg. Validation Accuracy: 0.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150 - Avg. Training Loss: 1.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150 - Avg. Validation Accuracy: 0.3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150 - Avg. Training Loss: 1.0785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150 - Avg. Validation Accuracy: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150 - Avg. Training Loss: 1.0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150 - Avg. Validation Accuracy: 0.4618\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150 - Avg. Training Loss: 1.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150 - Avg. Validation Accuracy: 0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150 - Avg. Training Loss: 1.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150 - Avg. Validation Accuracy: 0.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150 - Avg. Training Loss: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150 - Avg. Validation Accuracy: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150 - Avg. Training Loss: 0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150 - Avg. Validation Accuracy: 0.3411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150 - Avg. Training Loss: 0.9424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150 - Avg. Validation Accuracy: 0.4115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150 - Avg. Training Loss: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150 - Avg. Validation Accuracy: 0.4429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150 - Avg. Training Loss: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150 - Avg. Validation Accuracy: 0.4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150 - Avg. Training Loss: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150 - Avg. Validation Accuracy: 0.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150 - Avg. Training Loss: 0.8906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150 - Avg. Validation Accuracy: 0.4037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150 - Avg. Training Loss: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150 - Avg. Validation Accuracy: 0.3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150 - Avg. Training Loss: 0.9206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150 - Avg. Validation Accuracy: 0.4438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150 - Avg. Training Loss: 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150 - Avg. Validation Accuracy: 0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150 - Avg. Training Loss: 0.8290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150 - Avg. Validation Accuracy: 0.3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/150 - Avg. Training Loss: 0.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/150 - Avg. Validation Accuracy: 0.4467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150 - Avg. Training Loss: 0.8298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150 - Avg. Validation Accuracy: 0.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150 - Avg. Training Loss: 0.8218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150 - Avg. Validation Accuracy: 0.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150 - Avg. Training Loss: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150 - Avg. Validation Accuracy: 0.3907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150 - Avg. Training Loss: 0.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150 - Avg. Validation Accuracy: 0.4237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150 - Avg. Training Loss: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150 - Avg. Validation Accuracy: 0.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150 - Avg. Training Loss: 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150 - Avg. Validation Accuracy: 0.4478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150 - Avg. Training Loss: 0.7530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150 - Avg. Validation Accuracy: 0.4618\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150 - Avg. Training Loss: 0.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150 - Avg. Validation Accuracy: 0.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150 - Avg. Training Loss: 0.7467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150 - Avg. Validation Accuracy: 0.4401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150 - Avg. Training Loss: 0.6876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150 - Avg. Validation Accuracy: 0.4218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150 - Avg. Training Loss: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150 - Avg. Validation Accuracy: 0.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/150 - Avg. Training Loss: 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/150 - Avg. Validation Accuracy: 0.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150 - Avg. Training Loss: 0.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150 - Avg. Validation Accuracy: 0.3605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150 - Avg. Training Loss: 0.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150 - Avg. Validation Accuracy: 0.5514\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150 - Avg. Training Loss: 0.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150 - Avg. Validation Accuracy: 0.5698\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/150 - Avg. Training Loss: 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/150 - Avg. Validation Accuracy: 0.4752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/150 - Avg. Training Loss: 0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/150 - Avg. Validation Accuracy: 0.5998\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150 - Avg. Training Loss: 0.5864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150 - Avg. Validation Accuracy: 0.5340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/150 - Avg. Training Loss: 0.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/150 - Avg. Validation Accuracy: 0.3968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150 - Avg. Training Loss: 0.5754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150 - Avg. Validation Accuracy: 0.3690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150 - Avg. Training Loss: 0.5208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150 - Avg. Validation Accuracy: 0.4210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/150 - Avg. Training Loss: 0.5137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/150 - Avg. Validation Accuracy: 0.5282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150 - Avg. Training Loss: 0.5607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150 - Avg. Validation Accuracy: 0.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/150 - Avg. Training Loss: 0.4915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/150 - Avg. Validation Accuracy: 0.4044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150 - Avg. Training Loss: 0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150 - Avg. Validation Accuracy: 0.5239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150 - Avg. Training Loss: 0.4970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150 - Avg. Validation Accuracy: 0.4942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150 - Avg. Training Loss: 0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150 - Avg. Validation Accuracy: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/150 - Avg. Training Loss: 0.5256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/150 - Avg. Validation Accuracy: 0.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150 - Avg. Training Loss: 0.4445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150 - Avg. Validation Accuracy: 0.4936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150 - Avg. Training Loss: 0.4521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150 - Avg. Validation Accuracy: 0.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/150 - Avg. Training Loss: 0.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/150 - Avg. Validation Accuracy: 0.4890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150 - Avg. Training Loss: 0.4354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150 - Avg. Validation Accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150 - Avg. Training Loss: 0.4390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150 - Avg. Validation Accuracy: 0.3493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150 - Avg. Training Loss: 0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150 - Avg. Validation Accuracy: 0.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150 - Avg. Training Loss: 0.4398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150 - Avg. Validation Accuracy: 0.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/150 - Avg. Training Loss: 0.4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/150 - Avg. Validation Accuracy: 0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/150 - Avg. Training Loss: 0.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/150 - Avg. Validation Accuracy: 0.5339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/150 - Avg. Training Loss: 0.4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/150 - Avg. Validation Accuracy: 0.5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150 - Avg. Training Loss: 0.3641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150 - Avg. Validation Accuracy: 0.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150 - Avg. Training Loss: 0.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150 - Avg. Validation Accuracy: 0.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150 - Avg. Training Loss: 0.3706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150 - Avg. Validation Accuracy: 0.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/150 - Avg. Training Loss: 0.3524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/150 - Avg. Validation Accuracy: 0.5201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150 - Avg. Training Loss: 0.3354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150 - Avg. Validation Accuracy: 0.5320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/150 - Avg. Training Loss: 0.3515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/150 - Avg. Validation Accuracy: 0.5377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150 - Avg. Training Loss: 0.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150 - Avg. Validation Accuracy: 0.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 - Avg. Training Loss: 0.3451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 - Avg. Validation Accuracy: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 - Avg. Training Loss: 0.3269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 - Avg. Validation Accuracy: 0.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150 - Avg. Training Loss: 0.3005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150 - Avg. Validation Accuracy: 0.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150 - Avg. Training Loss: 0.3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150 - Avg. Validation Accuracy: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150 - Avg. Training Loss: 0.2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150 - Avg. Validation Accuracy: 0.6008\n",
      "New latest and best accuracy! Saving model checkpoint to ./trained_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/150 - Avg. Training Loss: 0.2910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/150 - Avg. Validation Accuracy: 0.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150 - Avg. Training Loss: 0.2694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150 - Avg. Validation Accuracy: 0.5361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150 - Avg. Training Loss: 0.2777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150 - Avg. Validation Accuracy: 0.4810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/150 - Avg. Training Loss: 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/150 - Avg. Validation Accuracy: 0.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150 - Avg. Training Loss: 0.2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150 - Avg. Validation Accuracy: 0.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/150 - Avg. Training Loss: 0.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/150 - Avg. Validation Accuracy: 0.5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/150 - Avg. Training Loss: 0.2439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/150 - Avg. Validation Accuracy: 0.5117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150 - Avg. Training Loss: 0.2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150 - Avg. Validation Accuracy: 0.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150 - Avg. Training Loss: 0.2376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150 - Avg. Validation Accuracy: 0.5156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/150 - Avg. Training Loss: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/150 - Avg. Validation Accuracy: 0.4249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150 - Avg. Training Loss: 0.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150 - Avg. Validation Accuracy: 0.3234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150 - Avg. Training Loss: 0.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150 - Avg. Validation Accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150 - Avg. Training Loss: 0.1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150 - Avg. Validation Accuracy: 0.5298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150 - Avg. Training Loss: 0.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150 - Avg. Validation Accuracy: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/150 - Avg. Training Loss: 0.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/150 - Avg. Validation Accuracy: 0.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/150 - Avg. Training Loss: 0.2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/150 - Avg. Validation Accuracy: 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150 - Avg. Training Loss: 0.2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150 - Avg. Validation Accuracy: 0.5326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150 - Avg. Training Loss: 0.2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150 - Avg. Validation Accuracy: 0.5254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150 - Avg. Training Loss: 0.1958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150 - Avg. Validation Accuracy: 0.5554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150 - Avg. Training Loss: 0.1805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150 - Avg. Validation Accuracy: 0.4011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150 - Avg. Training Loss: 0.1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150 - Avg. Validation Accuracy: 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150 - Avg. Training Loss: 0.1859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150 - Avg. Validation Accuracy: 0.5280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150 - Avg. Training Loss: 0.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150 - Avg. Validation Accuracy: 0.5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150 - Avg. Training Loss: 0.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150 - Avg. Validation Accuracy: 0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150 - Avg. Training Loss: 0.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150 - Avg. Validation Accuracy: 0.4879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/150 - Avg. Training Loss: 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/150 - Avg. Validation Accuracy: 0.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150 - Avg. Training Loss: 0.1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150 - Avg. Validation Accuracy: 0.4725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150 - Avg. Training Loss: 0.1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150 - Avg. Validation Accuracy: 0.4713\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)  # You can choose a different optimizer if you wish\n",
    "\n",
    "# Resume a previous training session if applicable\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_accuracy = checkpoint['accuracy']\n",
    "    warnings.warn(f\"\\n\\nFound model checkpoint at {CHECKPOINT_PATH}.\\n\"\n",
    "                  f\"Loaded model and optimizer from epoch {checkpoint['epoch']}.\")\n",
    "    warnings.warn(f\"\\n\\nValidation accuracy: {checkpoint['accuracy']}\")\n",
    "    warnings.warn(f\"\\n\\nLoss: {checkpoint['loss']}\")\n",
    "else:\n",
    "    start_epoch = 1\n",
    "    best_accuracy = float('-inf')\n",
    "    warnings.warn(\"\\n\\nNo model checkpoint found.\\nStarting from scratch.\")\n",
    "\n",
    "# IMPORTANT: Save/load the dataloaders to ensure same data order and data split across different runtimes\n",
    "if os.path.exists(DATALOADER_PATH):\n",
    "    checkpoint = torch.load(DATALOADER_PATH)\n",
    "    train_dataloader = checkpoint['train_dataloader']\n",
    "    val_dataloader = checkpoint['val_dataloader']\n",
    "    test_dataloader = checkpoint['test_dataloader']\n",
    "    warnings.warn(f\"\\n\\nFound saved dataloaders at {DATALOADER_PATH}.\\n\"\n",
    "                  f\"Loaded dataloaders (specifying a previous data order and data slit).\")\n",
    "else:\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=len(val_data), shuffle=False, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False, collate_fn=collate_fn)\n",
    "    torch.save({\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'val_dataloader': val_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "    }, DATALOADER_PATH)\n",
    "    warnings.warn(\"\\n\\nStarting with new data order and data slit.\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trained_model, loss_progress, val_progress = train_model(model, optimizer, train_dataloader, val_dataloader, epochs, best_accuracy)\n",
    "\n",
    "# Plot the training loss and validation progression on the same graph over epochs\n",
    "plt.plot(loss_progress, label='Training Loss')\n",
    "plt.plot(val_progress, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss/accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTpNICjlIaAs",
    "outputId": "e074fbb9-a063-48ca-fe01-d8d08b05e53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6868\n"
     ]
    }
   ],
   "source": [
    "# Get the model's R-squared score on the test data, this step should be quite\n",
    "# similar to what we have for the validation phase above\n",
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False, collate_fn=collate_fn)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in test_dataloader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    generate_outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=10)\n",
    "    decoded_preds = tokenizer.batch_decode(generate_outputs, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    try:\n",
    "      predicted_values = [float(pred) for pred in decoded_preds]\n",
    "      actual_values = [float(label) for label in decoded_labels]\n",
    "      test_score = sklearn.metrics.r2_score(predicted_values, actual_values)\n",
    "    except ValueError:\n",
    "      test_score = float('-inf')\n",
    "print(f\"Test Accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsU0eMzBX-nc"
   },
   "source": [
    "# Part 3: Comparison Study\n",
    "Let's look at alternative models commonly used in ML ([linear regression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html), [decision tree learning](https://scikit-learn.org/1.5/modules/tree.html), [random forest, XG boost](https://scikit-learn.org/1.5/modules/ensemble.html)) and have proven to be very powerful in modeling large datasets. You might have already learned some of them in this and other AI/ML-topic courses. SKLearn provides a fast and convenient pipeline for us to load up different ML models and train/cross-validate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4xDP6PiYUoC",
    "outputId": "3f2502a0-03c5-4d06-f16c-86b221538ae3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "Train Accuracy: 0.7493\n",
      "Validation Accuracy: 0.3533\n",
      "\n",
      "DecisionTreeRegressor:\n",
      "Train Accuracy: 1.0000\n",
      "Validation Accuracy: 0.1424\n",
      "\n",
      "RandomForestRegressor:\n",
      "Train Accuracy: 0.9832\n",
      "Validation Accuracy: 0.6362\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "Train Accuracy: 0.9788\n",
      "Validation Accuracy: 0.6804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_other_ML_models(X, y):\n",
    "    for model in [LinearRegression(),\n",
    "                  DecisionTreeRegressor(),\n",
    "                  RandomForestRegressor(),\n",
    "                  GradientBoostingRegressor()]:\n",
    "        scores = cross_validate(model, X, y, cv=5, return_train_score=True)\n",
    "        # Average over the different fold-divisions and print results\n",
    "        print(f\"{model.__class__.__name__}:\")\n",
    "        print(f\"Train Accuracy: {scores['train_score'].mean():.4f}\")\n",
    "        print(f\"Validation Accuracy: {scores['test_score'].mean():.4f}\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# Normalize the data for other ML models\n",
    "numeric_features = data.select_dtypes(include=['int64', 'float64'])\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(numeric_features.drop(columns=['MEDV']))\n",
    "\n",
    "train_other_ML_models(\n",
    "    X=scaled_features,\n",
    "    y=numeric_features['MEDV']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzqsJJnFY2k7"
   },
   "source": [
    "# Part 4: Final Report and Student's Reflection\n",
    "\n",
    "### 1. Report ALL the hyperparameters you've used in training the T5 model on the Boston house price prediction task (e.g. what is the train-val-test split percentage? how many epochs did you train the model? etc.).\n",
    "For the train-validation-test split I chose a 80%-10%-10% split which is a commonly used one. The other used hyperparameters are:\n",
    "- learning rate: 1e-4. It's a tradeoff between a high learning rate (e.g. 1e-2) that ensures fast convergence but with possible overshooting and a small learning rate (e.g. 1e-5) that converges to the optimal value without overshooting but very slowly.\n",
    "- epochs: 150. After some experiments I saw that it can be a good tradeoff between a significant impact on the overall performance and the computational complexity.\n",
    "- batch size: 16. I chose a smaller batch size so that the updates are more frequent and it fits well with the 150 epochs so that it can slowly but steadily converge to the optimal value.\n",
    "- weight decay: 1e-4. Used for regularization. I started with higher values but then I decreased it since I noticed it was performing better.\n",
    "\n",
    "### 2. Did you try different values for each hyperparameter? What are they? Which value(s) you have found to be the best at helping the model reach higher test accuracy?\n",
    "I tried many configurations for each hyperparameter:\n",
    "- learning rate: I tried higher learning rates like 1e-2, the convergence was fast but noisy on higher epochs, I also tried lower values like 1e-5 but it was too slow to converge to a good value.\n",
    "- epochs: I tried smaller values like 50 but it wasn't enough to achieve a good result. I then tried higher values like 150 and 250 to see if it could achieve better results. Since it's very computationally expensive I used the T4GPU on Google Colab to make the experiments run in a reasonable time.\n",
    "- batch size: I tried the standard 64 and I reached good results, but then I tried to lower it to 16 and it got better.\n",
    "- weight decay: I tried 1e-2 and then 1e-2. I noticed that with 1e-4 it performed better and the validation loss was constantly increasing without any big change in value towards higher epochs.\n",
    "\n",
    "### 3. Report the final model training loss and its accuracy on the held-out test data.\n",
    "Final model training loss: 0.1551\n",
    "\n",
    "Final validation accuracy: 0.4713\n",
    "\n",
    "Test accuracy: 0.6868\n",
    "\n",
    "### 4. What is the model's test accuracy (R-squared score) if it always answers with the average value over the housing prices in the dataset regardless of the input features? Did your trained model do better than that score?\n",
    "If the model always predicts the average value, 50% of the time it will predict a higher value and the remaining 50% it will predict a lower value. Assuming a uniform distribution of the values, we can say that the wrong prediction errors will cancel out, roughly giving an R-squared score of 0.\n",
    "\n",
    "The trained model performs better than that reaching a final accuracy of 0.6868 > 0\n",
    "\n",
    "### 5. There is no correct answer to this question. From your results, do you think it understands the human housing market? To what degree does it do/don't? how do you think the modality difference (the strict numerical pricing values versus the loosely defined textual price format) impacts the learning of our language model? did you notice highly discontinuous and erratic jumps in the model's validation score over the training epochs (e.g. it goes from -inf to -0.5 to -155.3 to 0.33, etc. in immediate steps)? why?\n",
    "##### Hint: pay attention to how the model's inner workings are numerical computations (matrix multiplications and additions) but it must work with and adapt to discrete tokens at its input and output endpoints.\n",
    "From the results, I think the model has a good but limited understanding of the housing market. I believe that the T5 model is not the best choice for this type of task, since it is good at performing text-like tasks and this is not the case since we're dealing with numerical values. I think that there are other models that better fit this type of problem (like decision trees). Despite that, it's true that it still achieves a good result almost reaching 69% of test accuracy.\n",
    "\n",
    "I noticed some discontinuous jumps in the model's validation score. My guess about the reason it happens is that we're dealing with numerical values that are mapped to tokens (discretized) so this mapping could lose some useful information/relation between numerical values.\n",
    "\n",
    "### 6. What part of the T5's pre-trained internet data you think might have helped its performance on our Boston house price prediction task?\n",
    "The data used to pretrain the model might include many real-estate information so the model could have captured some general domain knowledge useful to the prediction task. An example is that it could have been trained on some articles or forums discussing about the most important features to determine the final price so it exploited this inferred information to improve the predictions.\n",
    "\n",
    "### 7. What part of the T5's pre-trained internet data you think might have hurt its performance on our Boston house price prediction task?\n",
    "Due to the vast diversity of the internet data it might happen that the model chose to represent the numerical values in a wrong way, or in a non proper way so that it didn't capture many important information. An example is the numerical precision or the fact that in some domains/contexts the values 1 and 2, for instance, might be considered as very different things, while for most of our dataset's input features, they are not.\n",
    "\n",
    "### 8. Did you observe the model overfitting (complete memorization of) our training data? how do you know it did/didn't?\n",
    "I noticed the model overfitting in the first versions of the model I tried. In fact, the validation accuracy (after a while) started going back down, while the training one was improving. This is a clear sign of overfitting. For this reason, I decided to introduce in the following models a fix to this issue by adding regularization. I tried a couple of values for the weight decay until I got to a point where the model performance didn't suggest a strong presence of overfitting anymore. It's important to notice that despite that, a bit of overfitting was still present since it's hard to totally get rid of it.\n",
    "\n",
    "### 9. What is the perfect number of training epochs that you would use to prevent your model from overfitting this task? why?\n",
    "#####   - If it is impossible to prevent overfitting, explain why you think so.\n",
    "#####   - If it's trivial for the model to never overfit, explain why you think so.\n",
    "In general, choosing a high number of epochs leads to overfitting since we're leaving the model too much time to learn the noise present in the data rather than the actual underlying distribution.\n",
    "\n",
    "It's impossible (for me) to totally prevent overfitting. The best we can do is to minimize its impact on the model's performance. In my case, we can see from the results that the actual best performance was found at epoch 122, but the final one is not that far off, though. For this reason we could say that this model still has overfitting and the optimal epoch to stop in this case would have been 122.\n",
    "\n",
    "Another thing to notice is that the Boston housing dataset has around 500 samples so it's a relatively small dataset. On the other hand, T5 model has a huge number of parameters which could suggest that the model tries to learn very specific details and information about the dataset making the role of regularization and cross-validation very hard and also making overfitting quite impossible to avoid.\n",
    "\n",
    "### 11. How do you think you can improve the training algorithm or the dataset design or the model choice to do better at our Boston house price prediction task? what nuances you think is important in considering these choices?\n",
    "To improve the model performance I tried to reduce the impact of overfitting by adding regularization setting weight decay to 1e-4.\n",
    "\n",
    "Then I tried many different configurations to find the best tuning for the hyperparameters. I found that by choosing a moderate number of epochs (150) with a small learning rate (1e-4) the model smoothly reaches a good result.\n",
    "\n",
    "I also tried to implement early-stopping technique to prevent overfitting but it was hard to find good parameters to make it perform better than the current model.\n",
    "\n",
    "I also tried to use the learning rate scheduler to adjust the learning rate during the training process but it didn't show any significant improvement in the model's performance.\n",
    "\n",
    "### 12. Report the results of your comparison study (between the T5 with each of the other ML models)\n",
    "T5:\n",
    "\n",
    "Train Loss: 0.1551\n",
    "\n",
    "Validation Accuracy: 0.4713\n",
    "\n",
    "LinearRegression:\n",
    "\n",
    "Train Accuracy: 0.7493\n",
    "\n",
    "Validation Accuracy: 0.3533\n",
    "\n",
    "DecisionTreeRegressor:\n",
    "\n",
    "Train Accuracy: 1.0000\n",
    "\n",
    "Validation Accuracy: 0.1424\n",
    "\n",
    "RandomForestRegressor:\n",
    "\n",
    "Train Accuracy: 0.9832\n",
    "\n",
    "Validation Accuracy: 0.6362\n",
    "\n",
    "GradientBoostingRegressor:\n",
    "\n",
    "Train Accuracy: 0.9788\n",
    "\n",
    "Validation Accuracy: 0.6804\n",
    "\n",
    "By looking at the validation accuracies we can say that the T5 model performs better than simple models like linear regressor and decision tree, and it has similar performance to the two ensemble models.\n",
    "\n",
    "### 13. Why do you think each ML model does better/worse than the other? is your trained T5 achieving a better accuracy than some/all the other models? why do you think it might be doing better/worse than some/all of the other ML models?\n",
    "By looking at the final validation accuracies, we can say that Gradien Boosting got the best performance, followed by Random Forest, Linear Regression and Decision Tree.\n",
    "\n",
    "The fact that the T5 model performs better than simple models like linear regressor and decision tree, suggests that these models could be too simple to capture all the needed information to get to good results. On the other hand, it performs roughly the same as the two ensemble models, meaning that these models can capture as much useful information as the T5 model while preventing overfitting.\n",
    "\n",
    "Random Forest is an ensemble model that uses decision trees as base models, but it's able to achieve a 3-times better result than the simple decision tree model. This could be due to the fact that the Random Forest model, being a bagging model, can significantly reduce overfitting.\n",
    "\n",
    "### 14. Considering the training time and inference time of our T5 model versus the other ML models, do you think the accuracy that our T5 achieves was worth it? why?\n",
    "Considering all the reasoning done before, I think that, overall, the T5 model is not the best solution.\n",
    "\n",
    "For this specific type of task, I believe that an ensemble model like Gradient Boosting performs better, also taking into account that it takes way less time to train.\n",
    "\n",
    "We also need to consider that the results obtained by the T5 model are \"optimal\" (hoping that my parameter tuning process was an optimal choice), while the ML ensemble models used to compare the results (especially Random Forest and Gradient Boosting) were used in their standard form without any particular parameter choice, suggesting that they could achieve even better results with some further adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2WRhEY7VNCX"
   },
   "source": [
    "# Part 5: Submission (Deadline: before class - 9 AM at December 6th, 2024)\n",
    "\n",
    "We expect you to complete the TODOs, run all the code cells, and have the final outputs of those cells displayed in your submission. Your submission file should be a single .ipynb file (openable to Jupyter Notebook and Google Colab).\n",
    "\n",
    "Please submit your file to the course Blackboard."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
